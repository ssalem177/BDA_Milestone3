{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829a1b3-5e8e-4688-ab16-60f976562634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset, getting the new predictors\n",
    "\n",
    "ATI = pd.read_csv('ATI.csv')\n",
    "\n",
    "ATI = ATI[['revenue','imdb_score','budget','twitter_score','actors_score']]\n",
    "\n",
    "# Getting new extended predictors\n",
    "\n",
    "imdb2 = ATI[['imdb_score']] ** 2\n",
    "\n",
    "twitter2 = ATI[['twitter_score']] ** 2\n",
    "\n",
    "actors2 = ATI[['actors_score']] ** 2\n",
    "\n",
    "budget2 = ATI[['budget']] ** 2\n",
    "\n",
    "\n",
    "# 2 way interactions\n",
    "\n",
    "imdb_twitter = ATI[['imdb_score']].to_numpy() * ATI[['twitter_score']].to_numpy()\n",
    "\n",
    "imdb_budget = ATI[['imdb_score']].to_numpy() * ATI[['budget']].to_numpy()\n",
    "\n",
    "imdb_actors = ATI[['imdb_score']].to_numpy() * ATI[['actors_score']].to_numpy()\n",
    "\n",
    "\n",
    "budget_twitter = ATI[['budget']].to_numpy() * ATI[['twitter_score']].to_numpy()\n",
    "\n",
    "budget_actors = ATI[['budget']].to_numpy() * ATI[['actors_score']].to_numpy()\n",
    "\n",
    "\n",
    "twitter_actors = ATI[['twitter_score']].to_numpy() * ATI[['actors_score']].to_numpy()\n",
    "\n",
    "# 3 way interactions\n",
    "\n",
    "imdb_budget_twitter = ATI[['imdb_score']].to_numpy() * ATI[['twitter_score']].to_numpy() * ATI[['budget']].to_numpy()\n",
    "actors_budget_twitter = ATI[['actors_score']].to_numpy() * ATI[['twitter_score']].to_numpy() * ATI[['budget']].to_numpy()\n",
    "imdb_budget_actors = ATI[['imdb_score']].to_numpy() * ATI[['actors_score']].to_numpy() * ATI[['budget']].to_numpy()\n",
    "imdb_twitter_actors = ATI[['imdb_score']].to_numpy() * ATI[['twitter_score']].to_numpy() * ATI[['actors_score']].to_numpy()\n",
    "\n",
    "# 4 way interaction\n",
    "\n",
    "imdb_budget_twitter_actors = ATI[['imdb_score']].to_numpy() * ATI[['actors_score']].to_numpy() * ATI[['budget']].to_numpy() * ATI[['twitter_score']].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# New dataset with 15 predictors now added in\n",
    "\n",
    "ATI['imdb_twitter'] = imdb_twitter\n",
    "ATI['imdb_budget'] = imdb_budget\n",
    "ATI['imdb_actors'] = imdb_actors\n",
    "ATI['budget_twitter'] = budget_twitter\n",
    "ATI['budget_actors'] = budget_actors\n",
    "ATI['twitter_actors'] = twitter_actors\n",
    "ATI['imdb_budget_twitter'] = imdb_budget_twitter\n",
    "ATI['actors_budget_twitter'] = actors_budget_twitter\n",
    "ATI['imdb_budget_actors'] = imdb_budget_actors\n",
    "ATI['imdb_twitter_actors'] = imdb_twitter_actors\n",
    "ATI['imdb_budget_twitter_actors'] = imdb_budget_twitter_actors\n",
    "ATI[['imdb2']] = imdb2\n",
    "ATI[['twitter2']] = twitter2\n",
    "ATI[['actors2']] = actors2\n",
    "ATI[['budget2']] = budget2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21814f-a48c-4470-99a0-c30635746c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# getting the predictions\n",
    "\n",
    "ATI_preds = ATI[['budget','twitter_score','actors_score','imdb_score','imdb_twitter','imdb_budget','imdb_actors','budget_twitter','budget_actors','twitter_actors','imdb_budget_twitter','actors_budget_twitter','imdb_budget_actors','imdb_twitter_actors','imdb_budget_twitter_actors','imdb2','actors2','budget2','twitter2']]\n",
    "\n",
    "ATI_response = ATI[['revenue']]\n",
    "\n",
    "# High Budget - Low Budget split\n",
    "\n",
    "ATI_high = ATI[ATI['revenue'] > 1000000000]\n",
    "ATI_low = ATI[ATI['revenue'] < 1000000000]\n",
    "\n",
    "ATI_high_preds = ATI_high[['budget','twitter_score','actors_score','imdb_score','imdb_twitter','imdb_budget','imdb_actors','budget_twitter','budget_actors','twitter_actors','imdb_budget_twitter','actors_budget_twitter','imdb_budget_actors','imdb_twitter_actors','imdb_budget_twitter_actors','imdb2','actors2','budget2','twitter2']]\n",
    "ATI_high_response = ATI_high[['revenue']]\n",
    "\n",
    "ATI_low_preds = ATI_low[['budget','twitter_score','actors_score','imdb_score','imdb_twitter','imdb_budget','imdb_actors','budget_twitter','budget_actors','twitter_actors','imdb_budget_twitter','actors_budget_twitter','imdb_budget_actors','imdb_twitter_actors','imdb_budget_twitter_actors','imdb2','actors2','budget2','twitter2']]\n",
    "ATI_low_response = ATI_low[['revenue']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469f219-d7e4-4127-8b58-2c2442ca62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Subset Selection\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# initialising iterative variables\n",
    "\n",
    "r_score = 0\n",
    "r_new = 0\n",
    "new_col = None\n",
    "\n",
    "columns = [] # final list of columns\n",
    "\n",
    "while (r_new >= r_score) and (len(columns) < len(ATI.columns)): \n",
    "    if reg != None:\n",
    "        reg_old = reg # tracking previous model, useful for later on \n",
    "\n",
    "    # Also tracking previous datasets, useful for final testing\n",
    "\n",
    "    if (X_train,X_test) != None:\n",
    "\n",
    "        X_train_final, X_test_final = X_train, X_test\n",
    "        \n",
    "    new_pred = '' # new predictor that will improve R-score\n",
    "    r_score = r_new # old r-score\n",
    "    \n",
    "    if new_col != None:\n",
    "        columns.append(new_col)\n",
    "\n",
    "    r_max = 0\n",
    "    \n",
    "    for i in ATI_preds.columns:\n",
    "\n",
    "        if ((i in columns) == False): # making sure i is not a predictor\n",
    "\n",
    "            columns_new = columns.copy()\n",
    "        \n",
    "            columns_new.append(i)\n",
    "        \n",
    "            ATI_i = ATI[columns_new] # new dataset with temp new column added\n",
    "        \n",
    "            ATI_response = ATI[['revenue']]\n",
    "\n",
    "            # PreProcessing, source https://medium.com/@lomashbhuva/elastic-net-regression-the-ultimate-guide-to-combining-ridge-and-lasso-eec3395a0fa1\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(ATI_i)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_scaled, ATI_response, test_size=0.3, random_state=1774231)\n",
    "\n",
    "\n",
    "            # fitting model\n",
    "        \n",
    "            reg = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "            # testing it \n",
    "\n",
    "            r2 = reg.score(X_test,y_test)\n",
    "\n",
    "\n",
    "            # if r2 better than max, make it new max\n",
    "            if (r2 > r_max):\n",
    "                new_col = i\n",
    "                r_max = r2\n",
    "\n",
    "    r_new = r_max # next best r score value\n",
    "\n",
    "\n",
    "print(columns)\n",
    "print(r_new)\n",
    "\n",
    "print(mean_absolute_error(y_test,reg_old.predict(X_test_final)))\n",
    "# ANOVA test\n",
    "\n",
    "reg_old.coef_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd859350-9a98-4ec5-85ee-08401729ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab83db0-2b3b-45ec-ac58-a90337429855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet implementation, reference https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Measuring shifts in model performance for high ratios\n",
    "\n",
    "\n",
    "# HyperParameter selection\n",
    "\n",
    "alphas = [0.001,0.01,0.1,1]\n",
    "\n",
    "ell1 = [0.25,0.5,0.75]\n",
    "\n",
    "# PreProcessing, source https://medium.com/@lomashbhuva/elastic-net-regression-the-ultimate-guide-to-combining-ridge-and-lasso-eec3395a0fa1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(ATI_preds)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, ATI[['revenue']], test_size=0.3, random_state=1774231)\n",
    "\n",
    "\n",
    "# initalising numpy array for hyperparameter results values\n",
    "\n",
    "hyper_scores = [] # will have 12 rows as 3 ell1 vals, 4 alphas vals, so 12 combinations. 4 cols because adding in r_scores, mae vals\n",
    "\n",
    "for i in alphas:\n",
    "    \n",
    "    for j in ell1:\n",
    "        \n",
    "        elasticmodel = ElasticNet(alpha = i, l1_ratio = j, random_state = 1774231)\n",
    "\n",
    "        elasticmodel.fit(X_train,y_train)\n",
    "\n",
    "        preds = elasticmodel.predict(X_test)\n",
    "\n",
    "        # r_score\n",
    "\n",
    "        r = r2_score(y_test, preds)\n",
    "\n",
    "        # MAE\n",
    "\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        \n",
    "        # modifying hyper-parameter database\n",
    "\n",
    "        hyper_scores.append([i,j,r,mae])\n",
    "\n",
    "\n",
    "# turning into numpy array\n",
    "\n",
    "hyper_scores = np.array(hyper_scores)\n",
    "\n",
    "# turning into dataframe\n",
    "\n",
    "hyper_scores = pd.DataFrame(hyper_scores)\n",
    "\n",
    "print(hyper_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964957c-8283-4911-98ca-f56822f54583",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fbe31-ec1d-463a-8ae4-5c743489817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet implementation, reference https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# HyperParameter selection\n",
    "\n",
    "alphas = [0.001,0.01,0.1,1]\n",
    "\n",
    "\n",
    "# PreProcessing, source https://medium.com/@lomashbhuva/elastic-net-regression-the-ultimate-guide-to-combining-ridge-and-lasso-eec3395a0fa1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(ATI_preds)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, ATI_response, test_size=0.3, random_state=1774231)\n",
    "\n",
    "## LASSO\n",
    "\n",
    "# initalising hyperparameter results values\n",
    "\n",
    "hyper_scores_lasso = [] # will have 4 rows alphas vals. 4 cols because adding in r_scores, mae vals\n",
    "\n",
    "for i in alphas:\n",
    "    \n",
    "        \n",
    "        lasso = Lasso(alpha = i, random_state = 1774231)\n",
    "\n",
    "        lasso.fit(X_train,y_train)\n",
    "\n",
    "        preds = lasso.predict(X_test)\n",
    "\n",
    "        # r_score\n",
    "\n",
    "        r = r2_score(y_test, preds)\n",
    "\n",
    "        # MAE\n",
    "\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        \n",
    "        # modifying hyper-parameter database\n",
    "\n",
    "        hyper_scores_lasso.append([i,r,mae])\n",
    "\n",
    "\n",
    "# turning into numpy array\n",
    "\n",
    "hyper_scores_lasso = np.array(hyper_scores_lasso)\n",
    "\n",
    "# turning into dataframe\n",
    "\n",
    "hyper_scores_lasso = pd.DataFrame(hyper_scores_lasso)\n",
    "\n",
    "## RIDGE\n",
    "\n",
    "# initalising hyperparameter results values\n",
    "\n",
    "hyper_scores_ridge = [] # will have 4 rows alphas vals. 4 cols because adding in r_scores, mae vals\n",
    "\n",
    "for i in alphas:\n",
    "    \n",
    "        \n",
    "        ridge = Ridge(alpha = i, random_state = 1774231)\n",
    "\n",
    "        ridge.fit(X_train,y_train)\n",
    "\n",
    "        preds = ridge.predict(X_test)\n",
    "\n",
    "        # r_score\n",
    "\n",
    "        r = r2_score(y_test, preds)\n",
    "\n",
    "        # MAE\n",
    "\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        \n",
    "        # modifying hyper-parameter database\n",
    "\n",
    "        hyper_scores_ridge.append([i,r,mae])\n",
    "\n",
    "\n",
    "# turning into numpy array\n",
    "\n",
    "hyper_scores_ridge = np.array(hyper_scores_ridge)\n",
    "\n",
    "# turning into dataframe\n",
    "\n",
    "hyper_scores_ridge = pd.DataFrame(hyper_scores_ridge)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ebd1d-0ea5-4648-83ad-c1ba2ea813c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_ # coefficients for lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b35476-57cb-4ace-9af1-cec090b546ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.coef_  # coefficients for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e82efe-7059-47b0-b186-c535ee247be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_scores_ridge  # metrics for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fccc675-80d4-4b5e-9071-921e3ac54bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_scores_lasso # metrics for lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b86447-9944-40f0-9b89-4d07eca89e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference https://www.geeksforgeeks.org/machine-learning/random-forest-regression-in-python/\n",
    "\n",
    "# Random-Forest\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# tree depth vals\n",
    "mtry = [10,50,100]\n",
    "\n",
    "# predictors to consider for each split \n",
    "min_n = [2,5,10,15]\n",
    "\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for i in mtry:\n",
    "    for j in min_n:\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(ATI_preds, ATI_response, test_size=0.3, random_state=1774231)\n",
    "\n",
    "        # radom forest model/fit on training set, splitting on MAE\n",
    "        \n",
    "        regressor = RandomForestRegressor(n_estimators=i, criterion = \"absolute_error\", min_samples_split = j, random_state=1774231)\n",
    "\n",
    "        regressor.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "        # model testing on prediction\n",
    "        predictions = regressor.predict(x_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "\n",
    "        final_results.append([i,j,r2,mae])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d6b69-6803-4413-8ab1-d47aef2dbf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results # seeing results for different r2, mae vals. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
